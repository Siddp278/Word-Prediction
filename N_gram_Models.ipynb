{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N_gram Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Og57hVqwokT"
      },
      "source": [
        "import pickle\n",
        "import nltk\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k6fwQvRwsFA"
      },
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, GRU, Embedding, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnHsbyJiwtrz",
        "outputId": "c738b850-1497-4457-b31c-46492bd35884"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "print(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1ljhjwfowvR_",
        "outputId": "71b7e18d-cc26-4140-c798-d8e3e90777ef"
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/Dataset\")\n",
        "os.getcwd() "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/Dataset'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWe26udAw2Fd",
        "outputId": "9b5b7b1c-911a-4d2e-f668-93383d7a088f"
      },
      "source": [
        "with open(\"Pre Data/Movies.txt\", \"r\", encoding = \"utf-8\") as f:\n",
        "    data = f.read()\n",
        "    \n",
        "words = data.split()    \n",
        "print(\"Number of words:\", len(words))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words: 16264927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yphg4vZtw3M2",
        "outputId": "8caa322a-1d13-4b71-c6c4-5732eb5812d5"
      },
      "source": [
        "data[0:200]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i admit the great majority of films released before say are just not for me. of the dozen or so major silents i have viewed one i loved the crowd and two we are very good the last command and city lig'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHHryk5Ew4OH",
        "outputId": "27131ba6-5a84-4645-80de-ea6fc0ece4b6"
      },
      "source": [
        "fp = data[300000:1650000].split()\n",
        "word_count = len(fp)\n",
        "print(word_count)\n",
        "\n",
        "pre_data = data[300000:1650000]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyF85KIJB2gs"
      },
      "source": [
        "test_data = data[1650000:1850000]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PfttstoPW82t",
        "outputId": "4260a27f-5bf6-4f22-d21e-1c7b1df920d1"
      },
      "source": [
        "print(type(pre_data))\n",
        "pre_data[:22]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'scare me final destina'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlN607b-VhV3"
      },
      "source": [
        "def remove_dot(text):\n",
        "  text = re.sub(r'[^\\w\\s]','',text)\n",
        "  r = re.split(\"[^a-zA-Z\\d]+\",text)\n",
        "  ans = ' '.join([ i for i in r if len(i) > 0 ])\n",
        "  return ans\n",
        "\n",
        "pre_data = remove_dot(pre_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az2vd-xEB_LR"
      },
      "source": [
        "test_data = remove_dot(test_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yULl_A35WxpX",
        "outputId": "53da97fa-69bd-46ab-bb76-cc6a95ffd443"
      },
      "source": [
        "pre_data[:200]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'scare me final destination and did not scare me but the drag scenes made me squirm in my seatrating watching this movie after seeing the french original is like reading wikipedia summary after reading'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVdV_gTIxr7C",
        "outputId": "30485a6f-982b-43e8-b922-bebd3f1692dc"
      },
      "source": [
        "pre_data_tokens = pre_data.split(\" \")\n",
        "test_data_tokens = test_data.split(\" \")\n",
        "\n",
        "print('Unique Tokens: %d' % len(set(pre_data_tokens)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique Tokens: 16277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bc-V1gzyIOf",
        "outputId": "9d252d04-98c2-4f12-d597-ca091ea39757"
      },
      "source": [
        "pre_data_tokens[0:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scare',\n",
              " 'me',\n",
              " 'final',\n",
              " 'destination',\n",
              " 'and',\n",
              " 'did',\n",
              " 'not',\n",
              " 'scare',\n",
              " 'me',\n",
              " 'but']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkMoQ0u2w4WO",
        "outputId": "d20207e3-b81e-4172-bb93-bb3f53655740"
      },
      "source": [
        "length = 3 # for trigrams\n",
        "sequences = list()\n",
        "for i in range(length, len(pre_data_tokens)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = pre_data_tokens[i-length:i]\n",
        "\t# convert into a line\n",
        "\tline = ' '.join(seq)\n",
        "\t# store\n",
        "\tsequences.append(line)\n",
        " \n",
        "print(sequences[:2]) \n",
        "print('Total Sequences: %d' % len(sequences))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['scare me final', 'me final destination']\n",
            "Total Sequences: 250153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOFF9bZcCP2F",
        "outputId": "7269f36a-86da-469d-a2c5-04896c6e80bf"
      },
      "source": [
        "length = 3 # for trigrams\n",
        "sequences_test = list()\n",
        "for i in range(length, len(test_data_tokens)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = test_data_tokens[i-length:i]\n",
        "\t# convert into a line\n",
        "\tline = ' '.join(seq)\n",
        "\t# store\n",
        "\tsequences_test.append(line)\n",
        " \n",
        "print(sequences_test[:2]) \n",
        "print('Total Sequences: %d' % len(sequences_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a takura yamashita', 'takura yamashita koji']\n",
            "Total Sequences: 36572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJYj9wfw4fG"
      },
      "source": [
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwPOycXeyycm"
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "sequences_int = tokenizer.texts_to_sequences(sequences)\n",
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yBBILonCf7S"
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer.fit_on_texts(sequences_test)\n",
        "sequences_int_test = tokenizer.texts_to_sequences(sequences_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fok_grrrriEL",
        "outputId": "382e1a7c-1c0a-4407-dba5-89aa22e5303c"
      },
      "source": [
        "sequences_int[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2405, 69, 469]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g56lyzUvzD53",
        "outputId": "79058a78-46ce-4ede-a277-443753d15130"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjAy-z_YzHeh",
        "outputId": "32b8a622-76ec-4d5e-c4b0-9a2406b70ab3"
      },
      "source": [
        "sequences_int[0:2]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2405, 69, 469], [69, 469, 3767]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPcbz1MHzJ-K",
        "outputId": "ba97cc98-7c21-4d9f-e3f7-4e758515f2a7"
      },
      "source": [
        "length = 3\n",
        "print(len(sequences_int))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rld4g5NOzPVX",
        "outputId": "65a54c17-9dd5-4452-98ff-01dcfe5e31f1"
      },
      "source": [
        "sequences_array = np.array(sequences_int)\n",
        "sequences_array"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2405,   69,  469],\n",
              "       [  69,  469, 3767],\n",
              "       [ 469, 3767,    2],\n",
              "       ...,\n",
              "       [1582,    5,    3],\n",
              "       [   5,    3,  805],\n",
              "       [   3,  805,  435]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEkmVGKtCs4p",
        "outputId": "162430dc-5f4e-4725-db94-3a9f4efd90a2"
      },
      "source": [
        "sequences_array_test = np.array(sequences_int_test)\n",
        "sequences_array_test"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    3, 17511,  1341],\n",
              "       [17511,  1341, 16513],\n",
              "       [ 1341, 16513,  9649],\n",
              "       ...,\n",
              "       [   20,   767,    18],\n",
              "       [  767,    18,    14],\n",
              "       [   18,    14,     3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WmS0LVmL5cj",
        "outputId": "1a9561aa-f548-42a1-ca01-6890e7f0b6a4"
      },
      "source": [
        "len(sequences_array)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250153"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH_R86_5zbn5",
        "outputId": "100ebdd2-5d71-48cb-fde7-da4ca5ef4295"
      },
      "source": [
        "c=1\n",
        "h=0\n",
        "while(c!=0):\n",
        "    limit = len(sequences_array)\n",
        "    d =[]\n",
        "    c=0\n",
        "    for i in range(0 , limit):\n",
        "      # print(sequences_array[i])\n",
        "      l=len(sequences_array[i])\n",
        "      if(l!=length):\n",
        "        print(sequences_array[i])\n",
        "        sequences_array = np.delete(sequences_array, i, 0)\n",
        "            \n",
        "        c=1\n",
        "        print(\"error at \", i)\n",
        "        print(\"Deleting :_________________________ \") \n",
        "        h = h+1\n",
        "        break  \n",
        "\n",
        "print(\"Total deletion: \", h)  "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total deletion:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPXyWyCCCxxO",
        "outputId": "cbedd51c-5145-4bdd-aa84-c140b5c872f8"
      },
      "source": [
        "c=1\n",
        "h=0\n",
        "while(c!=0):\n",
        "    limit = len(sequences_array_test)\n",
        "    d =[]\n",
        "    c=0\n",
        "    for i in range(0 , limit):\n",
        "      # print(sequences_array[i])\n",
        "      l=len(sequences_array_test[i])\n",
        "      if(l!=length):\n",
        "        print(sequences_array_test[i])\n",
        "        sequences_array_test = np.delete(sequences_array_test, i, 0)\n",
        "            \n",
        "        c=1\n",
        "        print(\"error at \", i)\n",
        "        print(\"Deleting :_________________________ \") \n",
        "        h = h+1\n",
        "        break  \n",
        "\n",
        "print(\"Total deletion: \", h) "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total deletion:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNaC1D8ozq1D",
        "outputId": "38947ccc-6c75-4f68-e4a4-e99586c9cf79"
      },
      "source": [
        "sequences_final = np.array(sequences_array.tolist())\n",
        "sequences_final"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2405,   69,  469],\n",
              "       [  69,  469, 3767],\n",
              "       [ 469, 3767,    2],\n",
              "       ...,\n",
              "       [1582,    5,    3],\n",
              "       [   5,    3,  805],\n",
              "       [   3,  805,  435]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7h7w_aMC4pQ",
        "outputId": "60f187b0-8c78-4775-cc79-3d521cfc4152"
      },
      "source": [
        "sequences_final_test = np.array(sequences_array_test.tolist())\n",
        "sequences_final_test"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    3, 17511,  1341],\n",
              "       [17511,  1341, 16513],\n",
              "       [ 1341, 16513,  9649],\n",
              "       ...,\n",
              "       [   20,   767,    18],\n",
              "       [  767,    18,    14],\n",
              "       [   18,    14,     3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvBP6teo0Cdu",
        "outputId": "3ee75929-6d0f-4eab-c6c3-14b6de96b7b8"
      },
      "source": [
        "sequences_final.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250153, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ce4vkzF0Fm6"
      },
      "source": [
        "# separate into input and output\n",
        "X, y = sequences_final[:,:-1], sequences_final[:,-1]\n",
        "seq_length = X.shape[1]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oLjHXWZsGia",
        "outputId": "7ccd80fc-ccc1-4992-df4a-b383f375f00d"
      },
      "source": [
        "print(X[0], \"->\", y[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2405   69] -> 469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIkXv1feDPuj"
      },
      "source": [
        "X_test, y_test = sequences_final_test[:,:-1], sequences_final_test[:,-1]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyah6gEJMNiR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrpC34iMX24Y"
      },
      "source": [
        "X_ttr, X_tval, y_ttr, y_tval = train_test_split(X_test, y_test, test_size = 0.1, random_state = 42)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89uHNZ7LA83X",
        "outputId": "c8d358f3-fc29-4e1f-8073-09c76af35092"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 25, input_length=seq_length))\n",
        "# model.add(GRU(150, return_sequences=True))\n",
        "model.add(GRU(150, return_sequences=True))\n",
        "model.add(GRU(100))\n",
        "model.add(Dropout(0.4))\n",
        "# model.add(Dense(150, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "# es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "# compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X_tr, y_tr, batch_size=512, epochs=200)#, callbacks=[es_callback])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 2, 25)             406925    \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 2, 150)            79650     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 100)               75600     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16277)             1643977   \n",
            "=================================================================\n",
            "Total params: 2,206,152\n",
            "Trainable params: 2,206,152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "391/391 [==============================] - 9s 16ms/step - loss: 7.7431 - accuracy: 0.0550\n",
            "Epoch 2/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 6.7583 - accuracy: 0.0578\n",
            "Epoch 3/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 6.6329 - accuracy: 0.0605\n",
            "Epoch 4/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 6.4600 - accuracy: 0.0730\n",
            "Epoch 5/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 6.3444 - accuracy: 0.0832\n",
            "Epoch 6/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 6.1322 - accuracy: 0.1098\n",
            "Epoch 7/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.9796 - accuracy: 0.1225\n",
            "Epoch 8/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.8728 - accuracy: 0.1268\n",
            "Epoch 9/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.7749 - accuracy: 0.1325\n",
            "Epoch 10/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.7070 - accuracy: 0.1354\n",
            "Epoch 11/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.6194 - accuracy: 0.1417\n",
            "Epoch 12/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.5312 - accuracy: 0.1446\n",
            "Epoch 13/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.4640 - accuracy: 0.1488\n",
            "Epoch 14/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.4037 - accuracy: 0.1511\n",
            "Epoch 15/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.3385 - accuracy: 0.1548\n",
            "Epoch 16/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.2854 - accuracy: 0.1579\n",
            "Epoch 17/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.2313 - accuracy: 0.1619\n",
            "Epoch 18/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.1736 - accuracy: 0.1641\n",
            "Epoch 19/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.1403 - accuracy: 0.1655\n",
            "Epoch 20/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.0821 - accuracy: 0.1690\n",
            "Epoch 21/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.0347 - accuracy: 0.1731\n",
            "Epoch 22/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 5.0019 - accuracy: 0.1741\n",
            "Epoch 23/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.9470 - accuracy: 0.1794\n",
            "Epoch 24/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.9203 - accuracy: 0.1817\n",
            "Epoch 25/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.8857 - accuracy: 0.1837\n",
            "Epoch 26/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.8439 - accuracy: 0.1867\n",
            "Epoch 27/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.8197 - accuracy: 0.1885\n",
            "Epoch 28/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.7930 - accuracy: 0.1904\n",
            "Epoch 29/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.7486 - accuracy: 0.1946\n",
            "Epoch 30/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.7264 - accuracy: 0.1973\n",
            "Epoch 31/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.7052 - accuracy: 0.1992\n",
            "Epoch 32/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.6720 - accuracy: 0.2018\n",
            "Epoch 33/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.6484 - accuracy: 0.2036\n",
            "Epoch 34/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.6295 - accuracy: 0.2050\n",
            "Epoch 35/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.5927 - accuracy: 0.2100\n",
            "Epoch 36/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.5781 - accuracy: 0.2103\n",
            "Epoch 37/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.5657 - accuracy: 0.2117\n",
            "Epoch 38/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.5486 - accuracy: 0.2129\n",
            "Epoch 39/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.5258 - accuracy: 0.2159\n",
            "Epoch 40/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.5057 - accuracy: 0.2178\n",
            "Epoch 41/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.4771 - accuracy: 0.2219\n",
            "Epoch 42/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.4723 - accuracy: 0.2203\n",
            "Epoch 43/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.4535 - accuracy: 0.2222\n",
            "Epoch 44/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.4322 - accuracy: 0.2238\n",
            "Epoch 45/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.4279 - accuracy: 0.2249\n",
            "Epoch 46/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.4022 - accuracy: 0.2278\n",
            "Epoch 47/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.3862 - accuracy: 0.2307\n",
            "Epoch 48/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.3769 - accuracy: 0.2297\n",
            "Epoch 49/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.3653 - accuracy: 0.2314\n",
            "Epoch 50/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.3540 - accuracy: 0.2335\n",
            "Epoch 51/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.3355 - accuracy: 0.2354\n",
            "Epoch 52/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.3274 - accuracy: 0.2370\n",
            "Epoch 53/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.3263 - accuracy: 0.2376\n",
            "Epoch 54/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2973 - accuracy: 0.2400\n",
            "Epoch 55/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2905 - accuracy: 0.2391\n",
            "Epoch 56/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2794 - accuracy: 0.2405\n",
            "Epoch 57/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2667 - accuracy: 0.2420\n",
            "Epoch 58/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2629 - accuracy: 0.2418\n",
            "Epoch 59/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2571 - accuracy: 0.2435\n",
            "Epoch 60/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2340 - accuracy: 0.2457\n",
            "Epoch 61/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2221 - accuracy: 0.2453\n",
            "Epoch 62/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2323 - accuracy: 0.2462\n",
            "Epoch 63/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.2115 - accuracy: 0.2486\n",
            "Epoch 64/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1953 - accuracy: 0.2483\n",
            "Epoch 65/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1874 - accuracy: 0.2497\n",
            "Epoch 66/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1773 - accuracy: 0.2523\n",
            "Epoch 67/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1785 - accuracy: 0.2510\n",
            "Epoch 68/200\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 4.1680 - accuracy: 0.2512\n",
            "Epoch 69/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1531 - accuracy: 0.2531\n",
            "Epoch 70/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1557 - accuracy: 0.2529\n",
            "Epoch 71/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1533 - accuracy: 0.2548\n",
            "Epoch 72/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1343 - accuracy: 0.2555\n",
            "Epoch 73/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1215 - accuracy: 0.2569\n",
            "Epoch 74/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1372 - accuracy: 0.2540\n",
            "Epoch 75/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1147 - accuracy: 0.2579\n",
            "Epoch 76/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.1025 - accuracy: 0.2591\n",
            "Epoch 77/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0907 - accuracy: 0.2607\n",
            "Epoch 78/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0980 - accuracy: 0.2603\n",
            "Epoch 79/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0852 - accuracy: 0.2608\n",
            "Epoch 80/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0837 - accuracy: 0.2612\n",
            "Epoch 81/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0768 - accuracy: 0.2607\n",
            "Epoch 82/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0677 - accuracy: 0.2627\n",
            "Epoch 83/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0567 - accuracy: 0.2642\n",
            "Epoch 84/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0467 - accuracy: 0.2656\n",
            "Epoch 85/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0554 - accuracy: 0.2641\n",
            "Epoch 86/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0323 - accuracy: 0.2679\n",
            "Epoch 87/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0363 - accuracy: 0.2652\n",
            "Epoch 88/200\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 4.0388 - accuracy: 0.2654\n",
            "Epoch 89/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0263 - accuracy: 0.2682\n",
            "Epoch 90/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0186 - accuracy: 0.2694\n",
            "Epoch 91/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0062 - accuracy: 0.2696\n",
            "Epoch 92/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0039 - accuracy: 0.2708\n",
            "Epoch 93/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0056 - accuracy: 0.2702\n",
            "Epoch 94/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 4.0090 - accuracy: 0.2697\n",
            "Epoch 95/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9961 - accuracy: 0.2693\n",
            "Epoch 96/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9845 - accuracy: 0.2716\n",
            "Epoch 97/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9815 - accuracy: 0.2730\n",
            "Epoch 98/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9730 - accuracy: 0.2722\n",
            "Epoch 99/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9705 - accuracy: 0.2758\n",
            "Epoch 100/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9698 - accuracy: 0.2740\n",
            "Epoch 101/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9673 - accuracy: 0.2738\n",
            "Epoch 102/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9645 - accuracy: 0.2753\n",
            "Epoch 103/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9465 - accuracy: 0.2772\n",
            "Epoch 104/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9429 - accuracy: 0.2772\n",
            "Epoch 105/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9521 - accuracy: 0.2756\n",
            "Epoch 106/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9356 - accuracy: 0.2788\n",
            "Epoch 107/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9240 - accuracy: 0.2784\n",
            "Epoch 108/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9416 - accuracy: 0.2767\n",
            "Epoch 109/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9179 - accuracy: 0.2779\n",
            "Epoch 110/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9260 - accuracy: 0.2794\n",
            "Epoch 111/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9209 - accuracy: 0.2785\n",
            "Epoch 112/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9155 - accuracy: 0.2803\n",
            "Epoch 113/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8979 - accuracy: 0.2813\n",
            "Epoch 114/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9005 - accuracy: 0.2825\n",
            "Epoch 115/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9102 - accuracy: 0.2808\n",
            "Epoch 116/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.9032 - accuracy: 0.2819\n",
            "Epoch 117/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8953 - accuracy: 0.2813\n",
            "Epoch 118/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8799 - accuracy: 0.2833\n",
            "Epoch 119/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8820 - accuracy: 0.2833\n",
            "Epoch 120/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8902 - accuracy: 0.2830\n",
            "Epoch 121/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8734 - accuracy: 0.2864\n",
            "Epoch 122/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8708 - accuracy: 0.2847\n",
            "Epoch 123/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8760 - accuracy: 0.2839\n",
            "Epoch 124/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8544 - accuracy: 0.2862\n",
            "Epoch 125/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8579 - accuracy: 0.2865\n",
            "Epoch 126/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8672 - accuracy: 0.2849\n",
            "Epoch 127/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8532 - accuracy: 0.2871\n",
            "Epoch 128/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8505 - accuracy: 0.2889\n",
            "Epoch 129/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8573 - accuracy: 0.2871\n",
            "Epoch 130/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8573 - accuracy: 0.2864\n",
            "Epoch 131/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8357 - accuracy: 0.2899\n",
            "Epoch 132/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8403 - accuracy: 0.2880\n",
            "Epoch 133/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8293 - accuracy: 0.2909\n",
            "Epoch 134/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8311 - accuracy: 0.2909\n",
            "Epoch 135/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8279 - accuracy: 0.2907\n",
            "Epoch 136/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8195 - accuracy: 0.2915\n",
            "Epoch 137/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8371 - accuracy: 0.2900\n",
            "Epoch 138/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8257 - accuracy: 0.2917\n",
            "Epoch 139/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8177 - accuracy: 0.2909\n",
            "Epoch 140/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8147 - accuracy: 0.2909\n",
            "Epoch 141/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8144 - accuracy: 0.2914\n",
            "Epoch 142/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7965 - accuracy: 0.2938\n",
            "Epoch 143/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8018 - accuracy: 0.2937\n",
            "Epoch 144/200\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 3.7952 - accuracy: 0.2946\n",
            "Epoch 145/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7981 - accuracy: 0.2931\n",
            "Epoch 146/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7950 - accuracy: 0.2946\n",
            "Epoch 147/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7901 - accuracy: 0.2954\n",
            "Epoch 148/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7970 - accuracy: 0.2924\n",
            "Epoch 149/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.8002 - accuracy: 0.2939\n",
            "Epoch 150/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7854 - accuracy: 0.2945\n",
            "Epoch 151/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7838 - accuracy: 0.2974\n",
            "Epoch 152/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7757 - accuracy: 0.2977\n",
            "Epoch 153/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7877 - accuracy: 0.2951\n",
            "Epoch 154/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7657 - accuracy: 0.2982\n",
            "Epoch 155/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7764 - accuracy: 0.2970\n",
            "Epoch 156/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7552 - accuracy: 0.2978\n",
            "Epoch 157/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7677 - accuracy: 0.2970\n",
            "Epoch 158/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7720 - accuracy: 0.2961\n",
            "Epoch 159/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7724 - accuracy: 0.2950\n",
            "Epoch 160/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7507 - accuracy: 0.2993\n",
            "Epoch 161/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7529 - accuracy: 0.2997\n",
            "Epoch 162/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7431 - accuracy: 0.3017\n",
            "Epoch 163/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7496 - accuracy: 0.2978\n",
            "Epoch 164/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7564 - accuracy: 0.2993\n",
            "Epoch 165/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7503 - accuracy: 0.2985\n",
            "Epoch 166/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7483 - accuracy: 0.2990\n",
            "Epoch 167/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7540 - accuracy: 0.2978\n",
            "Epoch 168/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7486 - accuracy: 0.2997\n",
            "Epoch 169/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7471 - accuracy: 0.2996\n",
            "Epoch 170/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7318 - accuracy: 0.3015\n",
            "Epoch 171/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7286 - accuracy: 0.3010\n",
            "Epoch 172/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7283 - accuracy: 0.3026\n",
            "Epoch 173/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7348 - accuracy: 0.2997\n",
            "Epoch 174/200\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 3.7232 - accuracy: 0.3018\n",
            "Epoch 175/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7253 - accuracy: 0.3028\n",
            "Epoch 176/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7241 - accuracy: 0.3028\n",
            "Epoch 177/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7260 - accuracy: 0.3013\n",
            "Epoch 178/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7115 - accuracy: 0.3032\n",
            "Epoch 179/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7232 - accuracy: 0.3018\n",
            "Epoch 180/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7241 - accuracy: 0.3012\n",
            "Epoch 181/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7201 - accuracy: 0.3032\n",
            "Epoch 182/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7076 - accuracy: 0.3043\n",
            "Epoch 183/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7123 - accuracy: 0.3012\n",
            "Epoch 184/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7186 - accuracy: 0.3032\n",
            "Epoch 185/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7002 - accuracy: 0.3051\n",
            "Epoch 186/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6934 - accuracy: 0.3055\n",
            "Epoch 187/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.7004 - accuracy: 0.3049\n",
            "Epoch 188/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6976 - accuracy: 0.3054\n",
            "Epoch 189/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6941 - accuracy: 0.3077\n",
            "Epoch 190/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6999 - accuracy: 0.3055\n",
            "Epoch 191/200\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 3.6929 - accuracy: 0.3063\n",
            "Epoch 192/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6857 - accuracy: 0.3055\n",
            "Epoch 193/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6868 - accuracy: 0.3066\n",
            "Epoch 194/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6823 - accuracy: 0.3068\n",
            "Epoch 195/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6786 - accuracy: 0.3086\n",
            "Epoch 196/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6832 - accuracy: 0.3084\n",
            "Epoch 197/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6810 - accuracy: 0.3072\n",
            "Epoch 198/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6847 - accuracy: 0.3071\n",
            "Epoch 199/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6777 - accuracy: 0.3098\n",
            "Epoch 200/200\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 3.6718 - accuracy: 0.3094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ed46192d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mrbEmi3ML6b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EPrVx5sBRDp"
      },
      "source": [
        "# saving the model\n",
        "# serialize to JSON\n",
        "json_file = model.to_json()\n",
        "with open(\"Model-JSON-N/Therapy.json\", \"w\") as file:\n",
        "   file.write(json_file)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"Model-JSON-N/Therapy-weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvpcSy_NA88X"
      },
      "source": [
        "\"\"\"\n",
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "file = open(json_file, 'r')\n",
        "model_json = file.read()\n",
        "file.close()\n",
        "loaded_model = model_from_json(model_json)\n",
        "# load weights\n",
        "loaded_model.load_weights(h5_file)\n",
        "\"\"\"\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2CJmnyxyRUr",
        "outputId": "09a95dfb-8b8d-433f-936b-6deb6eae6380"
      },
      "source": [
        "print(X_ttr[0], \"->\", y_ttr[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2640  737] -> 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE06xvgn7xEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414f9062-70ad-4a0c-a038-9f31d2796023"
      },
      "source": [
        "results = model.evaluate(X_val, y_val)\n",
        "print('Test accuracy: {0:.2f}%'.format(results[1]*100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1564/1564 [==============================] - 6s 4ms/step - loss: 6.9517 - accuracy: 0.1417\n",
            "Test accuracy: 14.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lspm_gZN5rf3"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWbcLnAR8cog"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hf6Fmhg94Ne"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHhTLZts-wMv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByPWzZJ9-3FC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vNduZGF0Sqp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTUpijRM1I4E"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXvYT5YU2ThP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}